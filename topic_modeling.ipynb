{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2020)\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import alpino\n",
    "from nltk.tag import UnigramTagger\n",
    "from random import shuffle\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_json('XXXXXXX.json', encoding='utf-8-sig', lines=True)\n",
    "print(DF.shape)\n",
    "DF.groupby('shop').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['submissionDateTime'] = pd.to_datetime(DF['submissionDateTime'], yearfirst=True, utc=True)\n",
    "DF = DF[['globalId', 'authorAgeRange', 'submissionDateTime', 'shop', 'cluster', 'rating', 'text', 'title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SORT BY MONTH AND POLARITY** (only takes into accounts 5 or 1 star reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "january_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'January')&(DF['rating'] ==5)].to_numpy()]\n",
    "january_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'January')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "february_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'February')&(DF['rating'] ==5)].to_numpy()]\n",
    "february_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'February')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "march_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'March')&(DF['rating'] ==5)].to_numpy()]\n",
    "march_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'March')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "april_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'April')&(DF['rating'] ==5)].to_numpy()]\n",
    "april_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'April')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "may_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'May')&(DF['rating'] ==5)].to_numpy()]\n",
    "may_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'May')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "june_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'June')&(DF['rating'] ==5)].to_numpy()]\n",
    "june_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'June')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "july_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'July')&(DF['rating'] ==5)].to_numpy()]\n",
    "july_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'July')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "august_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'August')&(DF['rating'] ==5)].to_numpy()]\n",
    "august_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'August')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "september_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'September')&(DF['rating'] ==5)].to_numpy()]\n",
    "september_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'September')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "october_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'October')&(DF['rating'] ==5)].to_numpy()]\n",
    "october_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'October')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "november_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'November')&(DF['rating'] ==5)].to_numpy()]\n",
    "november_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'November')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "december_pos = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'December')&(DF['rating'] ==5)].to_numpy()]\n",
    "december_neg = [x for x in DF.loc[(DF['submissionDateTime'].dt.strftime('%B') == 'December')&(DF['rating'] ==1)].to_numpy()]\n",
    "\n",
    "pos = [x for x in DF.loc[DF['rating'] ==5].to_numpy()]\n",
    "neg = [x for x in DF.loc[DF['rating'] ==1].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_func(XX):\n",
    "    obj_analysis = XX\n",
    "    texts = [item[6] for item in obj_analysis]\n",
    "    labels = [item[5] for item in obj_analysis]\n",
    "    labels = [1 if i > 3 else 0 for i in labels]\n",
    "    def preprocessing(text, pos_tags=False):\n",
    "        # tokenize into words\n",
    "        tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]   \n",
    "        stop = stopwords.words('dutch')  # remove stopwords\n",
    "        stop.extend(['mee', 'het', 'erg', 'wel', 'zeer', 'wij', 'ik', 'ben', 'jij', 'jullie', 'echt', \n",
    "                           'wel', 'heel', 'erg', 'mee', 'dus', 'maar']) #extra stopwords     \n",
    "        tokens = [token for token in tokens if token not in stop]\n",
    "        tokens = [word for word in tokens if len(word) >= 3] # remove words less than three characters\n",
    "        tokens = [word.lower() for word in tokens] # remove capitalization\n",
    "        lmtzr = WordNetLemmatizer()\n",
    "        tokens = [lmtzr.lemmatize(word) for word in tokens] # lemmatizing\n",
    "        preprocessed_text= ' '.join(tokens)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def preprocesser(list_of_texts): # turning lists into preprocessed lists\n",
    "        new = []\n",
    "        for item in list_of_texts:\n",
    "            new += [preprocessing(item)]\n",
    "        return new\n",
    "    \n",
    "    corpus = [r for r in preprocesser(texts)]\n",
    "\n",
    "    #selecting documents with highest subjectivity, based on relative number of present adjectives\n",
    "    training_corpus = alpino.tagged_sents() # dutch training corpus\n",
    "    unitagger = UnigramTagger(training_corpus)\n",
    "    pos_tag = unitagger.tag\n",
    "    corpus_POS = []  \n",
    "    for item in corpus:\n",
    "        tokens = nltk.word_tokenize(item)\n",
    "        pos_item = pos_tag(tokens)\n",
    "        new_sent = ['_'.join(t) for t in pos_item if t[1] is not None]\n",
    "        corpus_POS += [new_sent]\n",
    "    corpus_POS\n",
    "    \n",
    "    ADJ_list = [(1+i.count('adj')) / len(i) for i in corpus_POS] # relative number of adjectives per document\n",
    "    ADJ_indices = [i for i in range(len(ADJ_list)) if ADJ_list[i] > mean(ADJ_list)] # highly subjective document indexes  \n",
    "\n",
    "    corpus = [corpus[i] for i in ADJ_indices]\n",
    "    shuffle(corpus)\n",
    "    \n",
    "    vectorizer = CountVectorizer(min_df=4, max_df=0.3, ngram_range=(1,1))\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    X = pd.DataFrame(X.todense(),columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    lda_model = LatentDirichletAllocation(n_components=3, max_iter=10, learning_decay=0.7)\n",
    "    doc_topic = lda_model.fit_transform(X)\n",
    "\n",
    "    def display_topics(model, feature_names, no_top_words):\n",
    "        with open('results_topics_ELK.txt', 'a', encoding='utf-8-sig') as file: \n",
    "            file.write(str(datetime.now()) + '\\n')\n",
    "            if len(np.unique(np.array(obj_analysis)[:,3])) == 1:  #adds store specific\n",
    "                file.write(str(obj_analysis[0][3]) + ' | ') \n",
    "            file.write(str(obj_analysis[0][4])\n",
    "                   + str(' | Positive | ' + str(obj_analysis[0][2]) + '\\n\\n' if obj_analysis[0][5] > 3 \n",
    "                     else ' | Negative | '+ str(obj_analysis[0][2]) + '\\n\\n'))\n",
    "\n",
    "            for topic_idx, topic in enumerate(model.components_):\n",
    "                print(\"Topic %d:\" % (topic_idx),\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]) + '\\n')\n",
    "                file.write(\"Topic %d: \" % (topic_idx))    \n",
    "                file.write(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]])+'\\n')              \n",
    "        \n",
    "            # Log Likelyhood: Higher the better\n",
    "            print(\"Log Likelihood: \", lda_model.score(X))\n",
    "            file.write(\"Log Likelihood: \" + str(lda_model.score(X))+ ' \\n')\n",
    "            # Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "            print(\"Perplexity: \", lda_model.perplexity(X))\n",
    "            file.write(\"Perplexity: \" + str(lda_model.perplexity(X))+ ' \\n')\n",
    "            # See model parameters\n",
    "            print(lda_model.get_params())\n",
    "            file.write(str(lda_model.get_params())+ ' \\n')\n",
    "            file.write('\\n\\n\\n')\n",
    "            \n",
    "    no_top_words = 20\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    display_topics(lda_model, feature_names, no_top_words)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: scherm werkt het past hoesje helaas telefoon goed zit waardoor helemaal ook gsm alleen blijft protector gaat terug mooi zitten\n",
      "\n",
      "Topic 1: product het goed hoesje dit gebruik kwaliteit telefoon slecht bol jammer los apparaat echter zit zitten toestel com binnen prijs\n",
      "\n",
      "Topic 2: kabel geluid slecht geld kwaliteit goed keer slechte jaar het doet gekocht kapot binnen gebruiken maakt kopen helaas niet apparaat\n",
      "\n",
      "Log Likelihood:  -147642.30935581704\n",
      "Perplexity:  956.4739013795825\n",
      "{'batch_size': 128, 'doc_topic_prior': None, 'evaluate_every': -1, 'learning_decay': 0.7, 'learning_method': 'batch', 'learning_offset': 10.0, 'max_doc_update_iter': 100, 'max_iter': 10, 'mean_change_tol': 0.001, 'n_components': 3, 'n_jobs': None, 'perp_tol': 0.1, 'random_state': None, 'topic_word_prior': None, 'total_samples': 1000000.0, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "main_func(december_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [january_pos, january_neg,\n",
    "          february_pos, february_neg,\n",
    "          march_pos, march_neg,\n",
    "          april_pos, april_neg,\n",
    "          may_pos, may_neg,\n",
    "           june_pos, june_neg,\n",
    "           july_pos, july_neg,\n",
    "           august_pos, august_neg,\n",
    "           september_pos, september_neg,\n",
    "           october_pos, october_neg, \n",
    "           november_pos, november_neg,\n",
    "           december_pos, december_neg\n",
    "          ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in my_list:\n",
    "    main_func(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
